{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Code_test.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1FAyoFp90Skq3PCXHI3efPF_igTHeooAn",
      "authorship_tag": "ABX9TyNx+6hS91wIcu9m33zl+U4c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shcheon95/ANN_TWS/blob/master/Copy_of_Code_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQB7t6Er1rYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install mat73"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g7MBymh7np-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import scipy.io as sio \n",
        "import mat73 \n",
        "import torch from torch.autograd import Variable import \n",
        "torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP1fB8_g0aQv",
        "colab_type": "text"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import mat73\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# mkdir /content/drive/My Drive/TWS_Recon/prac_pytorch/cp_best\n",
        "# mkdir /content/drive/My Drive/TWS_Recon/prac_pytorch/cp_last\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "## Making Data\n",
        "mat_dum = mat73.loadmat('/content/drive/My Drive/TWS_Recon/prac_pytorch/mat_ann_input_TgmL_PgpcpL_N_ncstL_TrF2003T2014.mat')\n",
        "reg_input = mat_dum.get('reg_input')\n",
        "X_ = reg_input.get('pre_tr_2014');\n",
        "t_pre = reg_input.get('t_pre')\n",
        "X1 = np.transpose(X_)\n",
        "y0 = reg_input.get('tar_tr')\n",
        "y = y0[:,1]\n",
        "y1 = np.transpose(y)\n",
        "\n",
        "\n",
        "btsz = 1;\n",
        "learning_rate = 0.001\n",
        "epochs = 500\n",
        "sel_mode = 2\n",
        "\n",
        "\n",
        "class ANN_Tr_Dataset():\n",
        "     def __init__(self,tar_pick):\n",
        "mm\n",
        "\n",
        "     def __getitem__(self,index):\n",
        "         return self.x_data[index], self.y_data[index]\n",
        "\n",
        "     def __len__(self):\n",
        "         return self.len\n",
        "\n",
        "class ANN_Ev_Dataset():\n",
        "    def __init__(self,tar_pick):\n",
        "        mat_dum = mat73.loadmat('/content/drive/My Drive/TWS_Recon/prac_pytorch/mat_ann_input_TgmL_PgpcpL_N_ncstL_TrF2003T2014.mat')\n",
        "        reg_input = mat_dum.get('reg_input')\n",
        "        X_ = reg_input.get('pre_pre_2015');\n",
        "        y0 = reg_input.get('tar_p_2015')\n",
        "        y = y0[:,tar_pick]\n",
        "        self.len = X_.shape[0]\n",
        "        self.x_data = torch.from_numpy(X_)\n",
        "        self.y_data = torch.from_numpy(y)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "\n",
        "sm_ = sel_mode - 1\n",
        "dataset = ANNDataset(sm_)\n",
        "\n",
        "train_loader = DataLoader(dataset=dataset,batch_size = btsz, shuffle=True)\n",
        "\n",
        "# X = Variable(torch.from_numpy(X1), requires_grad=True)\n",
        "# y = Variable(torch.from_numpy(y1))\n",
        "\n",
        "if 0:\n",
        "    print('type of X: ',type(X))\n",
        "    print('shape of y: ',np.shape(y))\n",
        "    print(reg_input.keys())\n",
        "    type(reg_input)\n",
        "    a = 5\n",
        "    print('size of x: ',np.shape(X))\n",
        "    #print(dum_dum)\n",
        "    \n",
        "## Model setting up\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.fc1 = nn.Linear(42,10)\n",
        "#         self.fc2 = nn.Linear(10,10)\n",
        "#         self.fc3 = nn.Linear(10,1)\n",
        "#     def forward(self,x):\n",
        "#         x = nn.LeakyReLU(self.fc1(x))\n",
        "#         x = nn.LeakyReLU(self.fc2(x))\n",
        "#         x = self.fc3(x)\n",
        "#         return x\n",
        "# net = Net()\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(42,20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20,20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20,1)\n",
        ")\n",
        "\n",
        "net.cuda()\n",
        "\n",
        "\n",
        "\n",
        "####>>>>>>>>>>>>>>>>>>>>>>>>>   Optimizer --------------------------------------\n",
        "optimizer = optim.AdamW(net.parameters(),lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# create a loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss_cri_ =100000000000;\n",
        "# run the main training loop\n",
        "for epoch in range(epochs):\n",
        "    # learning_rate = learning_rate/(1+99*(epoch/epochs))\n",
        "    cum_loss = torch.zeros(1,1)\n",
        "    cum_loss.cuda()\n",
        "    for batch_idx, data_ in enumerate(train_loader,0):\n",
        "        # get the inputs\n",
        "        pre, target = data_\n",
        "        pre = pre.type(torch.cuda.FloatTensor)\n",
        "        target = target.cuda()\n",
        "        # wrap them in Variable\n",
        "        pre, target = Variable(pre,requires_grad=True), Variable(target)\n",
        "\n",
        "        # Forward pass:\n",
        "        net_out = net(pre)\n",
        "\n",
        "        # compute and print loss\n",
        "        # loss를 구하기 전에 타입을 맞추자!!!!!\n",
        "        net_out = net_out.float()\n",
        "        target = target.type(torch.cuda.FloatTensor)\n",
        "        loss = criterion(net_out, target)\n",
        "        \n",
        "        # print('loss: ',loss)\n",
        "        # print(net_out.type(),net_out)\n",
        "        # print(target.type(),target)\n",
        "\n",
        "        # Zero gradients, perform a backward pass, and update the weights.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # pre1 = torch.reshape(X[:,batch_idx],(1,42))\n",
        "        # target = y[batch_idx]\n",
        "        # pre = pre1.cuda()\n",
        "        # target = target.cuda()\n",
        "\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        # pre = pre.type(torch.cuda.FloatTensor)\n",
        "        # pre= torch.reshape(pre,(1,42))\n",
        "        # pre = Variable(pre)\n",
        "        # net_out = net(pre)\n",
        "        # net_out = net_out.float()\n",
        "        # target = target.type(torch.cuda.FloatTensor)\n",
        "        # loss = criterion(net_out, target)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        # log_interval = 20\n",
        "        cum_loss = cum_loss.cuda() + loss\n",
        "    if epoch%100 == 0:\n",
        "        print(epoch,'/',epochs)\n",
        "        print('loss: ', loss.data)\n",
        "        \n",
        "    \n",
        "    if cum_loss < loss_cri_:\n",
        "        loss_cri_ = cum_loss\n",
        "        checkpoint = {'model':net,'state_dict':net.state_dict(),\n",
        "                      'optimizer':optimizer.state_dict()}\n",
        "        torch.save(checkpoint,'/content/drive/My Drive/TWS_Recon/prac_pytorch/cp_best/best.py')\n",
        "        print('Improved LOSS : ',loss_cri_.item())\n",
        "\n",
        "\n",
        "# print(net_out,target)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-UW29W-YWcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(reg_input.keys())\n",
        "print(reg_input.get('tar_p_2015').shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un9shuQvSzfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    for parameter in model.parameters():\n",
        "        parameter.requires_grad = False\n",
        "\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model = load_checkpoint('/content/drive/My Drive/TWS_Recon/prac_pytorch/cp_best/best.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGJysDd6TSi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import forecasting_metrics as fm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import imageio\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "print(reg_input.keys())\n",
        "t_tr = reg_input.get('t_tr_2014')\n",
        "y_ = dataset.y_data\n",
        "x = dataset.x_data\n",
        "print('y.shape: ',y_.shape)\n",
        "print('x.shape: ',x.shape)\n",
        "pred_ = torch.zeros(144,1)\n",
        "for k in range(x.shape[0]):\n",
        "    xin_ = x[k,:]\n",
        "    # print(xin_.dtype)\n",
        "    xin_ = np.reshape(xin_,(1,-1))\n",
        "    # print('xin_.type: ',xin_.type)\n",
        "\n",
        "    xin_ = xin_.type(torch.cuda.FloatTensor)\n",
        "    # print(xin_.size())\n",
        "    pred_[k] = model(xin_)\n",
        "    # print(pred_[k].item(),y[k].item())\n",
        "\n",
        "pred = pred_.detach().numpy()\n",
        "# print(pred)\n",
        "y_ = y_.numpy()\n",
        "# pred_ = pred_.detach.numpy()\n",
        "\n",
        "print(fm.nrmse(pred,y_))\n",
        "print('r2: ', r2_score(pred,y_))\n",
        "print(t_tr.shape)\n",
        "print(y_.shape)\n",
        "print(pred.shape)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(t_tr,y_,'r',t_tr,pred,'k--')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd55boAETzZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoU84uGsTtFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9anVBlCK2W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GQkAl-b0dNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install mat73\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCrv2WMP0qUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWPLYHWy0tT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(pre)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}